{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Luther: Ebertron\n",
    "--\n",
    "Ozzie Liu - ozzie@ozzieliu.com\n",
    "\n",
    "Part 2/3 - Review wrangling and processing \n",
    "\n",
    "This IPython notebook documents the process of wrangling and cleaning data before it can be used for regression and exploratory data analysis. Results are pickled for use in the next part\n",
    "\n",
    "### Process:\n",
    "1. <a href='#1'>Open and merge OMDB flatfile</a>\n",
    "2. <a href='#2'>Open and merge Rotten Tomatoes file with ratings.</a>\n",
    "3. <a href='#3'>Create dummy variables for genres</a>\n",
    "\n",
    "### Packages:\n",
    "- numpy: for some numerical analysis\n",
    "- pandas: for data frames\n",
    "- pickle: to pickle things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load the metadata scraped in Part 1\n",
    "review_metadata = pickle.load(open('ebert_reviews.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Open and merge OMDB flatfile\n",
    "<a id='1'></a>\n",
    "See <a href='http://www.omdbapi.com/'>OMDB</a> for more information on obtaining the flatfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load the OMDB flatfile\n",
    "omdb = pd.read_csv('omdb0116/omdbMovies.txt', sep = '\\t', error_bad_lines=False)\n",
    "\n",
    "# omdb = pickle.load(open('omdb.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## That's a lot of movies. We're not concerned with all of those. I start by getting rid of movies before 1980s\n",
    "omdb = omdb[omdb['Year'] > 1980]\n",
    "\n",
    "## Define a helper function to strip the 'min' from runtime column\n",
    "def strip_min(time):\n",
    "    try:\n",
    "        return int(time.split()[0])\n",
    "    except:\n",
    "        return time\n",
    "## and apply strip_min() to the entire column.\n",
    "omdb['Runtime'] = omdb['Runtime'].apply(strip_min, 1)\n",
    "\n",
    "## Keep only movies with runtime longer than 30 minutes\n",
    "omdb = omdb[omdb['Runtime'] >= 30]\n",
    "## and if rating is not adult\n",
    "omdb = omdb[omdb['Rating'] != 'X']\n",
    "## and has imdbVotes\n",
    "omdb = omdb[np.isfinite(omdb['imdbVotes'])]\n",
    "## that's more than 1200 votes\n",
    "omdb = omdb[omdb['imdbVotes'] > 1200]\n",
    "## and also has a metacritic score\n",
    "omdb = omdb[np.isfinite(omdb['Metacritic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now merge the two lists with a left join on the movie title\n",
    "review_df = review_metadata.merge(omdb, how='left', on='Title')\n",
    "## Select the columns that I want\n",
    "review_df = review_df[['Title', 'EbertStars', 'Year_x', 'URL', 'ID', 'imdbID', 'Genre', 'Metacritic', 'imdbRating', 'imdbVotes', 'Country', 'Awards']]\n",
    "\n",
    "## Note: because we're joining on movie titles, there may be duplicate rows for movies with the same title.\n",
    "## This step is omitted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Open and merge Rotten Tomatoes file with ratings.\n",
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open tab separated CSV file\n",
    "tomatoes = pd.read_csv('omdb0116/tomatoes.txt', sep='\\t')\n",
    "## Since we're using IMDB's movie ID to join RT ratings, I remove any movies that doesn't have ID\n",
    "review_df = review_df[np.isfinite(review_df['ID'])]\n",
    "## Merge with tomatoes\n",
    "review_df = review_df.merge(tomatoes, how = 'left', on = 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create dummy variables for all genres\n",
    "<a id='3'></a>\n",
    "Take the current string of genres and make it into a true list first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_df = pickle.load(open('movie_df.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take a string of genre and split them into a list of genres for easy searching later\n",
    "Input: string of genres listed\n",
    "Output: list of genres\n",
    "\"\"\"\n",
    "\n",
    "def list_genres(my_string):\n",
    "    return my_string.replace(',', '').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Apply the helper function and get the set of genres.\n",
    "movie_df['Genre'] = movie_df['Genre'].apply(list_genres, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_list = list()\n",
    "for gl in movie_df['Genre']:\n",
    "    genre_list = genre_list + gl\n",
    "# genre_set = set(movie_df['Genre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genre_set = set(genre_list)\n",
    "print genre_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make dummy variables for all the genres.\n",
    "Input is the row in which we'll apply in the dataFrame\n",
    "Output is a Series of columns corresponding to that genre. 1 indicated that it is of that genre. \n",
    "0 indicates that it's not\n",
    "\"\"\"\n",
    "\n",
    "def dummy_genres(row):\n",
    "    genrelist = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary','Drama','Family','Fantasy',\n",
    "          'History','Horror','Music','Musical','Mystery','News','Romance','Sci-Fi','Short','Sport','Thriller','War','Western']\n",
    "    \n",
    "    result = [0]*len(genrelist)\n",
    "    \n",
    "    for index, gen in enumerate(genrelist):\n",
    "        result[index] = int(gen in row['Genre'])\n",
    "            \n",
    "    return pd.Series({'Action':result[0],'Adventure':result[1],'Animation':result[2],'Biography':result[3],'Comedy':result[4],\n",
    "                      'Crime':result[5],'Documentary':result[6],'Drama':result[7],'Family':result[8],'Fantasy':result[9],\n",
    "                      'History':result[10],'Horror':result[11],'Music':result[12],'Musical':result[13],'Mystery':result[14],\n",
    "                      'News':result[15],'Romance':result[16],'Sci-Fi':result[17],'Short':result[18],'Sport':result[19],\n",
    "                      'Thriller':result[20],'War':result[21],'Western':result[22]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Apply to create new columns for those genre.\n",
    "movie_df[['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary','Drama','Family','Fantasy',\n",
    "          'History','Horror','Music','Musical','Mystery','News','Romance',\n",
    "          'Sci-Fi','Short','Sport','Thriller','War','Western']] = movie_df.apply(dummy_genres, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Considering that Ebert watches a lot foreign films, we should add this as a genre.\n",
    "## I define foreign as any film that was not made in an english speaking country\n",
    "def split_country(s):\n",
    "    try:\n",
    "        return s.split(',')\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "movie_df['Country'] = movie_df['Country'].apply(split_country, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_foreign(row):\n",
    "    country = set(row['Country'])\n",
    "    english = set(['USA', 'UK', 'Canada'])\n",
    "\n",
    "    if len(english & country) > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "movie_df['foreign'] = movie_df.apply(check_foreign, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now remove some columns that I don't care for anymore:\n",
    "movie_df = movie_df.drop(['Year_x', 'URL', 'ID', 'imdbVotes', 'Awards', 'Country', 'Image', 'Meter', 'Reviews', 'Fresh',\n",
    "                         'Rotten', 'Consensus', 'userMeter', 'DVD', 'BoxOffice', 'Production', 'Website', 'lastUpdated'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pickle and store file to use in regression and EDA Notebook\n",
    "pickle.dump(movie_df, open('movie_reviews_full.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
