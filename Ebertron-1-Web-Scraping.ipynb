{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Luther: Ebertron\n",
    "--\n",
    "Ozzie Liu - ozzie@ozzieliu.com\n",
    "\n",
    "Part 1/3 - Webpage scraping for roger ebert's movie reviews on www.rogerebert.com  \n",
    "\n",
    "This IPython notebook documents the process of scraping web data to analyze and predict Mr. Ebert's reviews with other movie review data.\n",
    "\n",
    "### Process:\n",
    "1. <a href='#1'>Collecting movie review metadata from www.rogerebert.com/reviews</a>\n",
    "2. <a href='#2'>Collecting movie review body from each review webpage</a>\n",
    "\n",
    "### Packages:\n",
    "- requests - fetch HTML pages\n",
    "- BeautifulSoup: web scraping\n",
    "- time: to add in a sleep delay when scraping\n",
    "- tqdm: a nifty tool to show progress bar\n",
    "- pandas: for data frames\n",
    "- pickle: to pickle things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Collecting movie review metadata from main review page\n",
    "<a id='1'/></a>\n",
    "On www.rogerebert.com/reviews, I wanted to collect the following information:\n",
    "- Movie title\n",
    "- URL of movie review page\n",
    "- Star ratings\n",
    "- Year of review\n",
    "\n",
    "Unfortunately, the main review webpage does not lend itself to easy data scraping. The page is dynamically generated with an infinity scroll that loads a few movie reviews at a time. So I literally scrolled down for a few minutes to get about 22 years of data. Then I saved the HTML locally to load into BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Open locally saved HTML file and create a BeautifulSoup object\n",
    "soup = BeautifulSoup(open('ebert_reviews20.html'), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Select all elements of <figure class=\"movie review\">. \n",
    "## This returns a ResultSet which is just a list of results\n",
    "all_reviews = soup('figure', {'class':'movie review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function goes through the locally cached webpage of rogerebert.com/reviews and parse each movie reviews' name,\n",
    "rating, year, and URL.\n",
    "Input is a BeautifulSoup ResultSet\n",
    "Output is a dataframe with movie name, review URL, # of stars, and year of review in a nice DataFrame \n",
    "\"\"\"\n",
    "def scrape_eberts_review(review_set):\n",
    "    review_list = list()\n",
    "    \n",
    "    for movie in review_set:\n",
    "        ## Since there's only one <a> link with a href, just return that\n",
    "        url = movie.a.get('href')\n",
    "        \n",
    "        ## Grab the title, which is the text of the 2nd <a> tag\n",
    "        title = movie.find_all('a')[1].text\n",
    "        \n",
    "        ## Calculate the star rating by adding the <i> that's a full star and <i> that's a half star\n",
    "        stars = len(movie.find_all('i', {'class':'icon-star-full'})) + 0.5 * len(movie.find_all('i', {'class':'icon-star-half'}))\n",
    "        \n",
    "        ## Get the year in the class:release year. Since some movies don't have an year listed, use try-except.\n",
    "        try:\n",
    "            year = movie.find('span', {'class':'release-year'}).text[1:-1]\n",
    "        except:\n",
    "            year = ''\n",
    "        ## Add the data into the list\n",
    "        review_list.append([title, stars, year, url])\n",
    "    \n",
    "    ## Create a data frame with respective column names and return the data frame\n",
    "    df = pd.DataFrame(review_list, columns = ['Title', 'EbertStars', 'Year', 'URL'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>EbertStars</th>\n",
       "      <th>Year</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Spectacular Now</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/the-spectacular-now-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Chess</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/computer-chess-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>At Any Price</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>/reviews/at-any-price-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blancanieves</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>/reviews/blancanieves-2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deceptive Practice: The Mysteries and Mentors ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/deceptive-practice-the-mysteries-and-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To the Wonder</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/to-the-wonder-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From Up on Poppy Hill</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/from-up-on-poppy-hill-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Host</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/the-host-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ginger and Rosa</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/ginger-and-rosa-2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>On the Road</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>/reviews/on-the-road-2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  EbertStars  Year  \\\n",
       "0                                The Spectacular Now         4.0  2013   \n",
       "1                                     Computer Chess         2.0  2013   \n",
       "2                                       At Any Price         4.0  2012   \n",
       "3                                       Blancanieves         4.0  2012   \n",
       "4  Deceptive Practice: The Mysteries and Mentors ...         3.0  2013   \n",
       "5                                      To the Wonder         3.5  2013   \n",
       "6                              From Up on Poppy Hill         2.5  2013   \n",
       "7                                           The Host         2.5  2013   \n",
       "8                                    Ginger and Rosa         3.0  2013   \n",
       "9                                        On the Road         2.0  2013   \n",
       "\n",
       "                                                 URL  \n",
       "0                  /reviews/the-spectacular-now-2013  \n",
       "1                       /reviews/computer-chess-2013  \n",
       "2                         /reviews/at-any-price-2012  \n",
       "3                         /reviews/blancanieves-2012  \n",
       "4  /reviews/deceptive-practice-the-mysteries-and-...  \n",
       "5                        /reviews/to-the-wonder-2013  \n",
       "6                /reviews/from-up-on-poppy-hill-2013  \n",
       "7                             /reviews/the-host-2013  \n",
       "8                      /reviews/ginger-and-rosa-2013  \n",
       "9                          /reviews/on-the-road-2013  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Call the function and store the data frame\n",
    "review_df = scrape_eberts_review(all_reviews)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Collecting movie review body from each review page\n",
    "<a id='2'></a>\n",
    "With the list of movie review URLs, I want to go to each page and gather the MPAA rating, Runtime, Genre, and the\n",
    "body text of the review. I use `requests` to fetch the webpage and `BeautifulSoup` again to parse the elements I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "scrape_webpage(link) function takes the link of the review page, fetches the page, and return the requested \n",
    "fields in a data frame\n",
    "\"\"\"\n",
    "\n",
    "def scrape_webpage(link):\n",
    "    \n",
    "    ## Build the compete URL, fetch the page, and create the BeautifulSoup object\n",
    "    url = 'http://www.rogerebert.com/'+link\n",
    "    webpage = requests.get(url).text\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    \n",
    "    ## Find the <p> elements with their respective class, select the bold text, slice any unneeded characters,\n",
    "    ## and encode it to simple ascii text. Using try-except since some movies don't have those fields. \n",
    "    try:\n",
    "        mpaa = soup.find('p', {'class':'mpaa-rating'}).strong.text[6:].encode('ascii','ignore')\n",
    "    except:\n",
    "        mpaa = ''\n",
    "    try: \n",
    "        runningtime = soup.find('p', {'class':'running-time'}).strong.text[:3].strip().encode('ascii', 'ignore')\n",
    "    except:\n",
    "        runningtime = ''\n",
    "    try:\n",
    "        genres = soup.find('p', {'class':'genres'}).strong.text.encode('ascii', 'ignore').replace(',', '').split()\n",
    "    except:\n",
    "        genres = []\n",
    "    \n",
    "    ## Construct the review text by gathering all the <div class=reviewBody> elements, pulling out their child <p>,\n",
    "    ## and extracting their text into a list. Then join each separate paragraph into one body.\n",
    "    reviewbody = ' '.join([paragraph.text for paragraph in soup.find('div', {'itemprop':'reviewBody'}).find_all('p')])\n",
    "    \n",
    "    ## Return results as a list for each review URL\n",
    "    return [link, mpaa, runningtime, reviewbody]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## Iterate through each review page's URL from the previos data frame and call the scrape_movie(). Store each output\n",
    "## list in scraped_list, and turn it into a dataframe.\n",
    "## Use tqdm for a nifty progress bar to indicate progress. Since this could take a while.\n",
    "## Also sleep for a short time before calling another webpage. Maybe so I don't get blocked for being a DDOS attacker\n",
    "scraped_list = list()\n",
    "\n",
    "for movie in tqdm.tqdm(review_df['URL']):\n",
    "    scraped_list.append(scrape_webpage(movie))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "review_content = pd.DataFrame(scraped_list, columns = ['URL', 'Rating', 'Runtime', 'Review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/reviews/the-spectacular-now-2013</td>\n",
       "      <td>R</td>\n",
       "      <td>99</td>\n",
       "      <td>[Editor's note: Roger Ebert filed this review ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/reviews/computer-chess-2013</td>\n",
       "      <td></td>\n",
       "      <td>91</td>\n",
       "      <td>[Editor's note: Roger Ebert filed this review ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/reviews/at-any-price-2012</td>\n",
       "      <td>R</td>\n",
       "      <td>105</td>\n",
       "      <td>Ramin Bahrani, the best new American director ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/reviews/blancanieves-2012</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>104</td>\n",
       "      <td>Note: The following was reworked from a blog p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/reviews/deceptive-practice-the-mysteries-and-...</td>\n",
       "      <td>NR</td>\n",
       "      <td>88</td>\n",
       "      <td>This is another of Roger Ebert's final reviews...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL Rating Runtime  \\\n",
       "0                  /reviews/the-spectacular-now-2013      R      99   \n",
       "1                       /reviews/computer-chess-2013             91   \n",
       "2                         /reviews/at-any-price-2012      R     105   \n",
       "3                         /reviews/blancanieves-2012  PG-13     104   \n",
       "4  /reviews/deceptive-practice-the-mysteries-and-...     NR      88   \n",
       "\n",
       "                                              Review  \n",
       "0  [Editor's note: Roger Ebert filed this review ...  \n",
       "1  [Editor's note: Roger Ebert filed this review ...  \n",
       "2  Ramin Bahrani, the best new American director ...  \n",
       "3  Note: The following was reworked from a blog p...  \n",
       "4  This is another of Roger Ebert's final reviews...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Finally, pickle the two resulting dataframes for the next step for data wrangling\n",
    "# pickle.dump(review_df, open('review_metadata.pkl', 'wb'))\n",
    "pickle.dump(review_df, open('ebert_reviews.pkl', 'wb'))\n",
    "pickle.dump(review_content, open('review_content.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
